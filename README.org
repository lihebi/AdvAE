#+TITLE: Visual Defense
* Ideas

How to produce image that not looking awkward to human? Consider the
sunglass paper. Adding a sunglass will not make us feel awkward. So
the key is, to compute the image that comply with noise.

* Install
Clone https://github.com/carlini/nn_robust_attacks into
=~/github/reading/nn_robust_attacks= (and modify the python path in
the code).

python packages
- tensorflow-gpu
- keras
- cleverhans
- foolbox

* Implementation

1. I should have a CNN model. Probably a baseline model for mnist first.
2. I will add my loss term, the gradient of Z w.r.t. x
3. see if this CNN still works

4. plug in FGSM and CW-L2

** STARTED accuracy 

Now I would like to run an attack with bounded allowed distortion, and
calculate the accuracy of my defense. The attacks:

- [ ] FGSM
- [ ] iFGSM
- [ ] CW (it does not have a bound). I have to decide which
  implementation of CW to use

I need to compare the performance with other defenses:
- [ ] iterative adv training with PGD attack
- [X] l2 input gradient regularizer 

I need to run on the following dataset:
- [X] mnist
- [ ] cifar
- [ ] imagenet  

** TODO checkpoint
I need checkpoint to reduce experiment time

** available implementation references

- madry mnist challenge: https://github.com/MadryLab/mnist_challenge
- input gradient regularizer: https://github.com/dtak/adversarial-robustness-public
- tensorflow-adversarial https://github.com/gongzhitaao/tensorflow-adversarial
- cleverhans: https://github.com/tensorflow/cleverhans
- foolbox: https://github.com/bethgelab/foolbox

** TODO define a lasso that sets the gradients to 0 when lower than a threshold

* Adv Denoiser Training

4. (optional) alternatively train denoiser and CNN, so that
the precision is still good. This may have equivalent effect as
training denoiser using high level feature guidance

4.1 FIXME probably also consider training for from clean x to x and to
logits, as that is the whole model

5. (optional) ensamble for different CNN architecture

This will affect the loaded variables. So load variables after this.

** TODOs        
        
- test whether this works for CW
- test whether this works for different CNN structure out of box, or even FC
- test for CIFAR and ImageNet
- visualize what the denoiser is doing on adv images
- plot the training and loss
- analyze how the different loss terms work. Even if the loss does
  not seem to decrease, it might act as a regularizer. Try removing it
  in the train step, and observe if that term increases and goes out
  of control.
- see whether it is necessary any more to use high layers of CNN.
- investigate whether increasing denoiser capacity helps with defense
  against CW
- ensemble different CNN architecture. I suspect that the rec terms
  actually act as regularizer for different CNNs. We'll see.
- analyze the difference, pros and cons, compared to generative methods.


* Archive
** DONE group lasso?
   CLOSED: [2019-04-10 Wed 01:01]

** DONE test the cw-l2 attack
   CLOSED: [2019-04-10 Wed 01:02]
1. the l0 distortion comparison
2. the visual comparison (not visible)
** DONE read other defense papers
   CLOSED: [2019-04-10 Wed 01:02]
** DONE plot distortion, accuracy graph
   CLOSED: [2019-04-10 Wed 01:02]
** DONE the L0 distortion and thresholded L0
   CLOSED: [2019-04-10 Wed 01:02]
** DONE try different optimizer
   CLOSED: [2019-04-10 Wed 01:02]
** DONE the distortion of CWL2
   CLOSED: [2019-04-10 Wed 01:02]
avg: Distortion: L2: 1.5010, L1: 16.0486, L0: 769.3000

** DONE the distortion of CWL0
   CLOSED: [2019-04-10 Wed 01:02]

For the first 0: Distortion: L2: 3.0370, L1: 11.1007, L0: 14.0000
The average of 10: Distortion: L2: 3.6233, L1: 19.5815, L0: 29.0000
